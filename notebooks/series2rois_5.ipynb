{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Preambule__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T08:31:28.809028Z",
     "start_time": "2020-09-17T08:31:28.801211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T08:31:29.271458Z",
     "start_time": "2020-09-17T08:31:28.810333Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T08:31:30.191457Z",
     "start_time": "2020-09-17T08:31:29.335318Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## importing stuff\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from time import sleep\n",
    "from sys import path as syspath\n",
    "syspath.append(os.path.expanduser(\"~/srdjan_functs/\"))\n",
    "import javabridge\n",
    "from bioformats import JARS as bfJARS\n",
    "javabridge.start_vm(class_path=bfJARS, max_heap_size=\"20G\")\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from islets.Recording import Recording, parse_leica\n",
    "from islets.utils import get_filterSizes\n",
    "from general_functions import td_nanfloor, td2str\n",
    "from copy import deepcopy\n",
    "\n",
    "from jupyter_plotly_dash import JupyterDash\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "\n",
    "def cellTransform(cellvalue, id=None, verbose=False):\n",
    "    import numpy as np\n",
    "    \n",
    "    if issubclass(type(cellvalue),(bool,np.bool_)):\n",
    "        if verbose:\n",
    "            print (\"creating a checklist\")\n",
    "        out = dcc.Checklist(id=id,\n",
    "                             options=[{\"label\":\"✔\" if cellvalue else \"✘\",\"value\":None}],\n",
    "                             value=[None]*(1-int(cellvalue)),\n",
    "                             labelStyle={\n",
    "                                 \"color\":\"green\" if cellvalue else \"red\",\n",
    "#                                  \"padding\":\"3px\"\n",
    "                             }\n",
    "                            )\n",
    "#     elif issubclass(type(cellvalue),(dict,)):\n",
    "#         out = dcc.Checklist(id=id,\n",
    "#                              options=[{\"label\":(str(k).replace(\" \",\"\")+(\"✔\" if cellvalue[k] else \"✘\")), \"value\":k} for k in cellvalue],\n",
    "#                              value = [k for k in cellvalue if not cellvalue[k]],\n",
    "# #                              style={\"height\":\"10px\",},\n",
    "#                              labelStyle={\n",
    "#                                  \"width\":\"100px\",\n",
    "#                                  \"display\":\"block\"\n",
    "#                                         }\n",
    "#                             )\n",
    "    elif issubclass(type(cellvalue),(str,int,float,np.int_)):\n",
    "        out = cellvalue\n",
    "    else:\n",
    "        out = str(cellvalue)\n",
    "    return html.Div(out,style={\n",
    "                                 \"font-family\":\"monospace\",\n",
    "                                 \"font-size\":\"14px\",\n",
    "                             },)\n",
    "#     if issubclass(type(value),str):\n",
    "\n",
    "def mystyle(col):\n",
    "    return {\"border\":'thin lightgrey solid',\n",
    "            \"text-align\": \"left\" if \"pickle\" in col else None,\n",
    "            \"width\": {\n",
    "                \"Series Durations\":\"120px\",\n",
    "                \"Duration\":\"100px\",\n",
    "                \"pickles\":\"150px\",\n",
    "                \"exp\":\"150px\",\n",
    "                \"series\":\"150px\",\n",
    "                     }.get(col),\n",
    "           }\n",
    "\n",
    "def generate_table(dataframe, max_rows=100):\n",
    "    rows = []\n",
    "    for i in range(min(len(dataframe), max_rows)):\n",
    "        row = []\n",
    "        for col in dataframe.columns:\n",
    "            value = dataframe.iloc[i][col]\n",
    "#             row.append(html.Td(value if issubclass(type(value),str) else dcc.Checklist(options=[{\"label\":\"item\"}]),\n",
    "# #                                style=style\n",
    "#                               ))\n",
    "            row.append(html.Td(cellTransform(value, id=f\"table-{col}-{i}\"),\n",
    "                               style=mystyle(col),\n",
    "                              ))\n",
    "        rows.append(html.Tr(row,\n",
    "                            style={\"border\":'thin lightgrey solid'},\n",
    "#                             border='thin lightgrey solid' \n",
    "                           ))\n",
    "\n",
    "    return html.Table(\n",
    "        # Header\n",
    "        [html.Tr([html.Th(col, style=mystyle(col)) for col in dataframe.columns],\n",
    "                            style={\"border\":'thick lightgrey solid'},)] +\n",
    "        # Body\n",
    "        rows,\n",
    "        style={\n",
    "            \"width\": \"1300px\",\n",
    "            \"text-align\":\"right\",\n",
    "            \"table-layout\": \"fixed\"\n",
    "        }\n",
    "    ) \n",
    "\n",
    "def import_data(recordings,forceMetadataParse=False):\n",
    "    status = []\n",
    "    ilifs = 0\n",
    "    for pathToRecording in tqdm(recordings):\n",
    "        print (\"#\"*20, pathToRecording)\n",
    "        try:\n",
    "            rec = Recording(pathToRecording)\n",
    "            if forceMetadataParse:\n",
    "                rec.parse_metadata()\n",
    "                rec.save_metadata()\n",
    "        except:\n",
    "            continue\n",
    "        recType = \"Nikon\" if pathToRecording.endswith(\".nd2\") else \"Leica\"\n",
    "\n",
    "        if recType==\"Leica\":\n",
    "            sers = parse_leica(rec)\n",
    "        else:\n",
    "            sers = [\"all\"]\n",
    "\n",
    "        analysisFolder = os.path.join(rec.folder, rec.Experiment+\"_analysis\")\n",
    "    #     if not os.path.isdir(analysisFolder):\n",
    "    #         os.makedirs(analysisFolder)\n",
    "\n",
    "        for ser in sers:\n",
    "            md = pd.Series()\n",
    "            md[\"path\"] = pathToRecording\n",
    "            md[\"exp\"] = os.path.split(pathToRecording)[-1]\n",
    "            md[\"series\"] = ser\n",
    "            try:\n",
    "                rec.import_series(ser, onlyMeta=True)\n",
    "            except:\n",
    "                print (f\"could not import {ser}\")\n",
    "                status += [md]\n",
    "                continue\n",
    "\n",
    "            saveDir = os.path.join(analysisFolder, ser)\n",
    "            for k,v in rec.Series[ser][\"metadata\"].items(): md[k] = v\n",
    "            fs = get_filterSizes(md.pxSize)\n",
    "    #         md[\"filter sizes\"] = fs\n",
    "            movieFilename = os.path.join(saveDir, rec.Experiment+\"_\"+ser+\".mp4\")\n",
    "            md[\"movie\"] = os.path.isfile(movieFilename)\n",
    "            if md[\"movie\"]:\n",
    "                md[\"movie size [MB]\"] = os.path.getsize(movieFilename)/10**6\n",
    "            for k in [\"bit depth\", \"Start time\", \"End time\",\"Name\"]: # , \"individual Series\"\n",
    "                try:    del md[k]\n",
    "                except: pass\n",
    "            md[\"Series Durations\"] = [\"%s [%s]\"%(r[\"Name\"].replace(\"Series\",\"S\"), td2str(td_nanfloor(r[\"Duration\"]))) for _,r in md[\"individual Series\"].iterrows()]\n",
    "            md[\"Series Durations\"] = \"\\n\".join(md[\"Series Durations\"])\n",
    "            del md[\"individual Series\"]\n",
    "    #         break\n",
    "            pklsDone = {}\n",
    "            imgsDone = {}\n",
    "            for fsize in fs:\n",
    "                pickleFile = os.path.join(saveDir, \".\".join(map(str,fsize))+\"_rois.pkl\")\n",
    "                imageFile = os.path.join(saveDir, \".image_\"+\".\".join(map(str,fsize))+\".png\")\n",
    "                pickleThere = os.path.isfile(pickleFile)\n",
    "                imageThere = os.path.isfile(imageFile)\n",
    "    #             if pickleThere:\n",
    "    #                 purge = True\n",
    "    #                 try:\n",
    "    #                     with open(pickleFile,\"rb\") as f:\n",
    "    #                         rr = pickle.load(f)\n",
    "    #                     purge = \"trace\" not in rr.df.columns\n",
    "    #                     if not purge: lastGood = pickleFile\n",
    "    #                 except:\n",
    "    #                     purge = True\n",
    "    #                 if purge:\n",
    "    #                     os.remove(pickleFile)\n",
    "    #                     if imageThere: os.remove(imageFile)\n",
    "                pklsDone[fsize] = pickleThere\n",
    "                imgsDone[fsize] = imageThere\n",
    "            md[\"pickles\"] = [pk if len(pk)>1 else pk[0] for pk in pklsDone.keys()]\n",
    "            md[\"(re)do pickles\"] = all(pklsDone.values())\n",
    "    #         md[\"images\"] = pklsDone\n",
    "    #         md[\"allDone\"] = np.array(list(pklsDone.values())).all() and md[\"movie done\"]\n",
    "            status += [dict(md.items())]\n",
    "        ilifs +=1\n",
    "    #     if ilifs>3:\n",
    "    #         break\n",
    "\n",
    "    return pd.DataFrame(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter Path to the folder you wish to process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T08:31:32.617285Z",
     "start_time": "2020-09-17T08:31:32.570278Z"
    }
   },
   "outputs": [],
   "source": [
    "# mainFolder = \"/data/Johannes/2020_09_03/\"\n",
    "# mainFolder = \"/data/Marjan/MB2020_lifs_2/\"\n",
    "mainFolder = \"/data/Sandra/2020/\"\n",
    "# mainFolder = \"/home/jupyter-sandra/\"\n",
    "\n",
    "recordings = []\n",
    "for cur,ds,fs in os.walk(mainFolder):\n",
    "    #### if you wish to restrict to only certain folders: ####\n",
    "    if \"2020_09\" not in cur: continue\n",
    "    for f in fs:\n",
    "        if not (f.endswith(\".lif\") or f.endswith(\".nd2\")):\n",
    "            continue\n",
    "        path = os.path.join(cur,f)\n",
    "        recordings += [path]\n",
    "recordings = sorted(recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T08:32:23.842033Z",
     "start_time": "2020-09-17T08:32:23.018807Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69e365d87a6476885c1ca0b287eb756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### /data/Sandra/2020/2020_09_08/Experiment65a.lif\n",
      "#################### /data/Sandra/2020/2020_09_08/Experiment65b.lif\n",
      "#################### /data/Sandra/2020/2020_09_08/Experiment65c.lif\n",
      "#################### /data/Sandra/2020/2020_09_08/Experiment65d.lif\n",
      "#################### /data/Sandra/2020/2020_09_10/Experiment66a.lif\n",
      "#################### /data/Sandra/2020/2020_09_11/Experiment67a.lif\n",
      "#################### /data/Sandra/2020/2020_09_11/Experiment67b.lif\n",
      "#################### /data/Sandra/2020/2020_09_11/Experiment67c.lif\n",
      "could not import Series039\n",
      "could not import Series040\n",
      "could not import Series042\n",
      "#################### /data/Sandra/2020/2020_09_11/Experiment67d.lif\n",
      "#################### /data/Sandra/2020/2020_09_16/Experiment68a.lif\n",
      "#################### /data/Sandra/2020/2020_09_16/Experiment68b.lif\n",
      "#################### /data/Sandra/2020/2020_09_16/Experiment68c.lif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status_orig = import_data(recordings, forceMetadataParse=False)\n",
    "\n",
    "status = deepcopy(status_orig)\n",
    "status.pxSize = status.pxSize.apply(\"{:.3f}\".format).astype(\"str\")\n",
    "for c in status.columns:\n",
    "    if \"Size\" in c and \"px\" not in c:\n",
    "        status[c.replace(\"Size\",\"\")] = status[c]\n",
    "        del status[c]\n",
    "\n",
    "status[\"location\"] = status.path.apply(lambda xi: os.path.split(xi)[0])\n",
    "status[\"Freq\"] = status[\"Frequency\"].apply(\"{:.1f}\".format).astype(\"str\")\n",
    "del status[\"Frequency\"]\n",
    "status[\"Duration\"] = status[\"Duration\"].apply(str).apply(lambda xi: xi.split()[-1].split(\".\")[0] )\n",
    "\n",
    "firstCols = [\"exp\", \"series\",\"movie\",\"Freq\",\"Duration\", \"movie size [MB]\", ]#,\"images\",]\n",
    "status = status[[c for c in firstCols if c in status]+[c for c in status.columns if c not in firstCols]]\n",
    "lastCols = [\"path\"]\n",
    "status = status[[c for c in status.columns if c not in lastCols]+lastCols]\n",
    "del status[\"pxUnit\"]\n",
    "del status[\"frame_range\"]\n",
    "try:\n",
    "    status[\"movie size [MB]\"] = status[\"movie size [MB]\"].round(1)\n",
    "except:\n",
    "    pass\n",
    "del status['gap']\n",
    "status.pickles = status.pickles.apply(lambda xi: str(xi)[1:-1].replace(\" \",\"\"))\n",
    "status = status[~status[list(\"XYZT\")].isna().all(1)]\n",
    "status = status[status.Z==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T08:43:05.103971Z",
     "start_time": "2020-09-17T08:43:04.986219Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "open the following link in a different tab (do not close this tab!): <a href=\"https://ctn.physiologie.meduniwien.ac.at/user/srdjan/app/endpoints/1ba9e4b9c427474da1a0dc618826a768/\">https://ctn.physiologie.meduniwien.ac.at/user/srdjan/app/endpoints/1ba9e4b9c427474da1a0dc618826a768/</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nshow = len(status)\n",
    "htmltable = generate_table(status.iloc[:nshow,:-2], max_rows=nshow)\n",
    "ixOrder = OrderedDict([(f\"table-{col}-{i}\",{\"col\":col,\"index\":i}) \\\n",
    "                       for i in range(nshow) for col in [\"movie\",\"(re)do pickles\"]])\n",
    "\n",
    "app = JupyterDash(__name__, width=1000)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div(\"Please check which of the following series you wish processed into movies/pickles. When done, please click on the button and follow instructions.\"),\n",
    "    html.Br(),\n",
    "    html.Button(id=\"save\",children=[\"Prepare script\"],n_clicks=0),\n",
    "    html.Div(id=\"output\"),\n",
    "    html.Div(htmltable,style={\"width\":\"1000px\"}),\n",
    "    html.Pre(id=\"marked\",children=\"------------\",\n",
    "             style={\n",
    "                \"width\": \"700px\",\n",
    "                \"height\": \"300px\",\n",
    "                'overflowX': 'scroll',\n",
    "                'overflowY': 'scroll',\n",
    "                \"display\": \"block\" if \"srdjan\" in os.getcwd() else \"none\",\n",
    "            }),\n",
    "],style={\"font-family\":\"Arial\"})\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"marked\",\"children\"),\n",
    "    [Input(k,\"value\") for k in ixOrder]\n",
    ")\n",
    "def see(*manyinputs):\n",
    "    print (manyinputs)\n",
    "    out = deepcopy(ixOrder)\n",
    "    for k,v in zip(out, manyinputs):\n",
    "        out[k][\"value\"] = v\n",
    "    out = list(out.values())\n",
    "    \n",
    "    for el in out:\n",
    "        el[\"value\"] = bool(len(el[\"value\"]))\n",
    "        i = status.index[el[\"index\"]]\n",
    "        el[\"rec\"] = status.loc[i,\"path\"]\n",
    "        el[\"ser\"] = status.loc[i,\"series\"]\n",
    "    out = pd.DataFrame(out)\n",
    "    output = \"\"\n",
    "    checklist_parse = []\n",
    "    for (rec,ser),ddf in out.groupby([\"rec\",\"ser\"]):\n",
    "        el = {\"rec\":rec,\"ser\":ser}\n",
    "        el[\"movie\"] = ddf.query(\"col=='movie'\")[\"value\"].iloc[0]\n",
    "        el[\"pickles\"] = ddf.query(\"col=='(re)do pickles'\")[\"value\"].iloc[0]\n",
    "#         for col in [\"movie\",\"(re)do pickles\"][:1]:\n",
    "#             el[col] = ddf.query(\"col==%s\"%col)[\"value\"]\n",
    "        checklist_parse += [el]\n",
    "    checklist_parse = pd.DataFrame(checklist_parse)\n",
    "#     output += \"\\n\"\n",
    "#     output += str(checklist_parse)\n",
    "#     output += \"\\n\"\n",
    "#     #################################### only movie begin\n",
    "#     for _,row in checklist_parse.iterrows():\n",
    "#         if not row[\"movie\"]:\n",
    "#             continue\n",
    "#         outFile = \"/.\".join(os.path.split(row.rec))+\".out\"\n",
    "#         line = \"\"\n",
    "# #         for _ in range(3):\n",
    "# #             line += f'''echo \"\" >> {outFile}\\n'''\n",
    "# #         line += f'''echo \"###### processing started at: $(date)\" >> {outFile}\\n'''\n",
    "#         line += f'''/data/useful_notebooks/process_single.py --recording=\"{row.rec}\" --series=\"{row.ser}\" --verbose --only-movie '''\n",
    "#         line += f\" >> {outFile}\"\n",
    "#         output += line+\"\\n\"\n",
    "#     #################################### only movie end\n",
    "    #################################### good begin\n",
    "    \n",
    "    for rec in checklist_parse.rec.unique():\n",
    "        outFile = \"/.\".join(os.path.split(rec))+\".out\"\n",
    "        output += f\"rm {outFile}\\n\"\n",
    "    for _,row in checklist_parse.iterrows():\n",
    "        if not row[[\"movie\",\"pickles\"]].any():\n",
    "            continue\n",
    "        outFile = \"/.\".join(os.path.split(row.rec))+\".out\"\n",
    "        line = \"\"\n",
    "        line += f\"rm {outFile}\\n\"\n",
    "        for _ in range(2):\n",
    "            line += f'''echo \"\" >> {outFile}\\n'''\n",
    "        line += f'''echo \"###### processing of {row.ser} started at: $(date)\" >> {outFile}\\n'''\n",
    "#         line += f'''time notebooks/process_single_1.py --recording=\"{row.rec}\" --series=\"{row.ser}\" --verbose'''\n",
    "        line += f'''time /data/useful_notebooks/process_single.py --recording=\"{row.rec}\" --series=\"{row.ser}\" --verbose'''\n",
    "        if not row.movie:\n",
    "            line += \" --leave-movie\"\n",
    "        if not row.pickles:\n",
    "            line += \" --leave-pickles\"\n",
    "        line += f\" >> {outFile}\"\n",
    "        output += line+\"\\n\"\n",
    "    #################################### good end\n",
    "    \n",
    "    return output\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"output\",\"children\"),\n",
    "    [Input(\"save\",\"n_clicks\")],\n",
    "    [State(\"marked\",\"children\")]\n",
    ")\n",
    "def prepare_script(n_clicks, text):\n",
    "    if n_clicks>0:\n",
    "        with open(os.path.expanduser(\"~/processing_script.sh\"),\"w\") as f:\n",
    "            f.write(text)\n",
    "        return dcc.Markdown(\"\"\"`processing_script.sh` prepared in your home folder.\n",
    "\n",
    "Just open new terminal and run: `bash processing_script.sh` \n",
    "\n",
    "You can then close the window and wait until the processing is finished. \n",
    "\n",
    "_(For now, there is no reallyt good way how to follow progress, sorry. You can try the cell below...)_\n",
    "\"\"\")\n",
    "\n",
    "app._repr_html_() \n",
    "link2app = \"https://ctn.physiologie.meduniwien.ac.at\"+app.get_app_root_url()\n",
    "HTML(f'open the following link in a different tab (do not close this tab!): <a href=\"{link2app}\">{link2app}</a>')\n",
    "# app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T08:43:08.069922Z",
     "start_time": "2020-09-17T08:43:08.003394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Experiment65a.lif     Series021  100%\n",
      "                         Series025  100%\n",
      "                         Series026  100%\n",
      "                      Series033-35  100%\n",
      "--------------------------------------------------\n",
      "   Experiment65b.lif   Series006-9  100%\n",
      "--------------------------------------------------\n",
      "   Experiment65c.lif     Series006  100%\n",
      "                      Series011-12  100%\n",
      "--------------------------------------------------\n",
      "   Experiment65d.lif     Series011  100%\n",
      "                      Series039-40  100%\n",
      "--------------------------------------------------\n",
      "   Experiment66a.lif     Series009  100%\n",
      "                      Series013-16  100%\n",
      "--------------------------------------------------\n",
      "   Experiment67a.lif  Series009-12  100%\n",
      "--------------------------------------------------\n",
      "   Experiment67b.lif   Series006-9    0%\n",
      "                      Series012-17    0%\n",
      "--------------------------------------------------\n",
      "   Experiment67c.lif     Series011   75%\n",
      "                         Series020    0%\n",
      "                         Series025    0%\n",
      "                         Series030    0%\n",
      "                         Series033  100%\n",
      "--------------------------------------------------\n",
      "   Experiment67d.lif   Series002-3    0%\n",
      "--------------------------------------------------\n",
      "   Experiment68a.lif     Series001    0%\n",
      "                       Series003-6    0%\n",
      "--------------------------------------------------\n",
      "   Experiment68b.lif     Series001    0%\n",
      "--------------------------------------------------\n",
      "   Experiment68c.lif     Series001    0%\n",
      "                         Series002    0%\n",
      "                         Series004    0%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hacky way to check progress\n",
    "for exp,df in status.groupby(\"exp\"):\n",
    "    printExp = True\n",
    "    for i,row in df.iterrows():\n",
    "        assert (status.loc[i].iloc[:2] == status_orig.loc[i,[\"exp\",\"series\"]]).all()\n",
    "        images = [f\".image_{'%i.%i'%fs if isinstance(fs,tuple) else fs}.png\" for fs in status_orig.loc[i,\"pickles\"]]\n",
    "        serDir = f\"{row.path}_analysis/{row.series}\"\n",
    "        if os.path.isdir(serDir):\n",
    "            imDone = sum([el in images for el in os.listdir(serDir)])\n",
    "        else:\n",
    "            imDone = 0\n",
    "        outPutFile = row.path.replace(row.exp, \".\"+row.exp+\".out\")\n",
    "        percDone = 100/len(images)*imDone\n",
    "    #     if percDone>=100: continue\n",
    "        print (\"%20s %13s  %3i%%\"%(row.exp if printExp else \"\", row.series, percDone))#, outPutFile, os.path.isfile(outPutFile))\n",
    "    #     if os.path.isfile(outPutFile):\n",
    "    #         output = open(outPutFile).read()\n",
    "    #         last = output#-1]\n",
    "    #         last = \"\\n\".join([\"\\t\"+l for l in last.splitlines()])\n",
    "    #         last += \"\\n\"\n",
    "    #         print(last)\n",
    "\n",
    "    #     break\n",
    "        printExp = False\n",
    "    print (\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Physio",
   "language": "python",
   "name": "physio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
