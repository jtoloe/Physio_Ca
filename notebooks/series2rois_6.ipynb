{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Preambule__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T09:32:59.712904Z",
     "start_time": "2020-11-19T09:32:59.704140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T09:33:03.269619Z",
     "start_time": "2020-11-19T09:32:59.888274Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm().pandas()\n",
    "\n",
    "import numpy as np\n",
    "np.corrcoef(*np.arange(10).reshape(2,-1))\n",
    "import javabridge\n",
    "from bioformats import JARS as bfJARS\n",
    "javabridge.start_vm(class_path=bfJARS, max_heap_size=\"20G\")\n",
    "## importing stuff\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from sys import exc_info\n",
    "import os\n",
    "import pickle\n",
    "from time import sleep\n",
    "from sys import path as syspath\n",
    "syspath.append(os.path.expanduser(\"~/srdjan_functs/\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from islets.Recording import Recording, parse_leica\n",
    "from islets.utils import get_filterSizes\n",
    "from general_functions import td_nanfloor, td2str\n",
    "from copy import deepcopy\n",
    "\n",
    "from jupyter_plotly_dash import JupyterDash\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T09:33:03.306566Z",
     "start_time": "2020-11-19T09:33:03.271435Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#%% other imports\n",
    "def cellTransform(cellvalue, id=None, verbose=False):\n",
    "    import numpy as np\n",
    "    \n",
    "    if issubclass(type(cellvalue),(bool,np.bool_)):\n",
    "        if verbose:\n",
    "            print (\"creating a checklist\")\n",
    "        out = dcc.Checklist(id=id,\n",
    "                             options=[{\"label\":\"✔\" if cellvalue else \"✘\",\"value\":None}],\n",
    "                             value=[None]*(1-int(cellvalue)),\n",
    "                             labelStyle={\n",
    "                                 \"color\":\"green\" if cellvalue else \"red\",\n",
    "#                                  \"padding\":\"3px\"\n",
    "                             }\n",
    "                            )\n",
    "#     elif issubclass(type(cellvalue),(dict,)):\n",
    "#         out = dcc.Checklist(id=id,\n",
    "#                              options=[{\"label\":(str(k).replace(\" \",\"\")+(\"✔\" if cellvalue[k] else \"✘\")), \"value\":k} for k in cellvalue],\n",
    "#                              value = [k for k in cellvalue if not cellvalue[k]],\n",
    "# #                              style={\"height\":\"10px\",},\n",
    "#                              labelStyle={\n",
    "#                                  \"width\":\"100px\",\n",
    "#                                  \"display\":\"block\"\n",
    "#                                         }\n",
    "#                             )\n",
    "    elif issubclass(type(cellvalue),(str,int,float,np.int_)):\n",
    "        out = cellvalue\n",
    "    else:\n",
    "        out = str(cellvalue)\n",
    "    return html.Div(out,style={\n",
    "                                 \"font-family\":\"monospace\",\n",
    "                                 \"font-size\":\"14px\",\n",
    "                             },)\n",
    "#     if issubclass(type(value),str):\n",
    "\n",
    "def mystyle(col):\n",
    "    return {\"border\":'thin lightgrey solid',\n",
    "            \"text-align\": \"left\" if \"pickle\" in col else None,\n",
    "            \"width\": {\n",
    "                \"Series Durations\":\"120px\",\n",
    "                \"Duration\":\"100px\",\n",
    "                \"pickles\":\"150px\",\n",
    "                \"exp\":\"150px\",\n",
    "                \"series\":\"150px\",\n",
    "                \"images\":\"150px\",\n",
    "                \"line scan\":\"100px\",\n",
    "                     }.get(col),\n",
    "           }\n",
    "\n",
    "def generate_table(dataframe, max_rows=100):\n",
    "    rows = []\n",
    "    for i in range(min(len(dataframe), max_rows)):\n",
    "        row = []\n",
    "        for col in dataframe.columns:\n",
    "            value = dataframe.iloc[i][col]\n",
    "#             row.append(html.Td(value if issubclass(type(value),str) else dcc.Checklist(options=[{\"label\":\"item\"}]),\n",
    "# #                                style=style\n",
    "#                               ))\n",
    "            row.append(html.Td(cellTransform(value, id=f\"table-{col}-{i}\"),\n",
    "                               style=mystyle(col),\n",
    "                              ))\n",
    "        rows.append(html.Tr(row,\n",
    "                            style={\"border\":'thin lightgrey solid'},\n",
    "#                             border='thin lightgrey solid' \n",
    "                           ))\n",
    "\n",
    "    return html.Table(\n",
    "        # Header\n",
    "        [html.Tr([html.Th(col, style=mystyle(col)) for col in dataframe.columns],\n",
    "                            style={\"border\":'thick lightgrey solid'},)] +\n",
    "        # Body\n",
    "        rows,\n",
    "        style={\n",
    "            \"width\": \"1300px\",\n",
    "            \"text-align\":\"right\",\n",
    "            \"table-layout\": \"fixed\"\n",
    "        }\n",
    "    ) \n",
    "\n",
    "\n",
    "def import_data(recordings,forceMetadataParse=False):\n",
    "    status = []\n",
    "    ilifs = 0\n",
    "    for pathToRecording in tqdm(recordings):\n",
    "        print (\"#\"*20, pathToRecording)\n",
    "        try:\n",
    "            rec = Recording(pathToRecording)\n",
    "            if forceMetadataParse:\n",
    "                rec.parse_metadata()\n",
    "                rec.save_metadata()\n",
    "        except:\n",
    "            continue\n",
    "        recType = \"Nikon\" if pathToRecording.endswith(\".nd2\") else \"Leica\"\n",
    "\n",
    "        if recType==\"Leica\":\n",
    "            sers = parse_leica(rec, index=True)\n",
    "        else:\n",
    "            sers = [(0,\"all\")]\n",
    "\n",
    "        analysisFolder = os.path.join(rec.folder, rec.Experiment+\"_analysis\")\n",
    "    #     if not os.path.isdir(analysisFolder):\n",
    "    #         os.makedirs(analysisFolder)\n",
    "#         rec.tag_linescans()\n",
    "#         print (sers)\n",
    "        for indices, ser in sers:\n",
    "            md = pd.Series(dtype=object)\n",
    "            md[\"path\"] = pathToRecording\n",
    "            md[\"exp\"] = os.path.split(pathToRecording)[-1]\n",
    "            md[\"series\"] = ser\n",
    "            index = indices[0]\n",
    "            ser0 = \"-\".join(ser.split(\"-\")[:-1]) if \"-\" in ser else ser\n",
    "            assert rec.metadata.loc[index,\"Name\"]==ser0\n",
    "#             singleLineScan = rec.metadata.loc[index,\"SizeY\"]>10\n",
    "            try:\n",
    "                rec.import_series(ser, onlyMeta=True,\n",
    "#                                   isLineScan=rec.metadata.loc[index,\"line scan\"]==\"single\"\n",
    "                                 )\n",
    "            except:\n",
    "                print (f\"could not import {ser}\")\n",
    "                status += [md]\n",
    "                continue\n",
    "            for k,v in rec.Series[ser][\"metadata\"].items():\n",
    "                md[k] = v\n",
    "                \n",
    "            saveDir = os.path.join(analysisFolder, ser)\n",
    "            for k in [\"bit depth\", \"Start time\", \"End time\",\"Name\"]: # , \"individual Series\"\n",
    "                try:    del md[k]\n",
    "                except: passs\n",
    "            md[\"Series Durations\"] = [\"%s [%s]\"%(r[\"Name\"].replace(\"Series\",\"S\"), td2str(td_nanfloor(r[\"Duration\"]))) for _,r in md[\"individual Series\"].iterrows()]\n",
    "            md[\"Series Durations\"] = \"\\n\".join(md[\"Series Durations\"])\n",
    "#             md[\"line scan\"] = md[\"SizeY\"]*md[\"pxSize\"]<6 # treat also this as a line scan\n",
    "            if md[\"line scan\"] != \"none\":\n",
    "                imagesDone = {}\n",
    "                for name in md[\"individual Series\"].Name:\n",
    "                    imageName = os.path.join(saveDir, rec.Experiment+\"_\"+name+\".png\")\n",
    "                    imagesDone[name] = os.path.isfile(imageName)\n",
    "                md[\"images\"] = imagesDone\n",
    "                md[\"images done\"] = all(imagesDone.values())\n",
    "            else:\n",
    "                movieFilename = os.path.join(saveDir, rec.Experiment+\"_\"+ser+\".mp4\")\n",
    "                md[\"movie\"] = os.path.isfile(movieFilename)\n",
    "                if md[\"movie\"]:\n",
    "                    md[\"movie size [MB]\"] = os.path.getsize(movieFilename)/10**6\n",
    "                pxSize = float(md.pxSize)\n",
    "                if pxSize<.7: pxSize*=2\n",
    "                fs = get_filterSizes(pxSize)\n",
    "                pklsDone = {}\n",
    "                imgsDone = {}\n",
    "                for fsize in fs:\n",
    "                    pickleFile = os.path.join(saveDir, \".\".join(map(str,fsize))+\"_rois.pkl\")\n",
    "                    imageFile = os.path.join(saveDir, \".image_\"+\".\".join(map(str,fsize))+\".png\")\n",
    "                    pickleThere = os.path.isfile(pickleFile)\n",
    "                    imageThere = os.path.isfile(imageFile)\n",
    "                    pklsDone[fsize] = pickleThere\n",
    "                    imgsDone[fsize] = imageThere\n",
    "                md[\"pickles\"] = [pk if len(pk)>1 else pk for pk in pklsDone.keys()]\n",
    "                md[\"(re)do pickles\"] = all(pklsDone.values())\n",
    "            del md[\"individual Series\"]\n",
    "            status += [dict(md.items())]\n",
    "        ilifs +=1\n",
    "    #     if ilifs>3:\n",
    "    #         break\n",
    "\n",
    "    return pd.DataFrame(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter Path to the folder you wish to process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T09:33:30.060255Z",
     "start_time": "2020-11-19T09:33:30.039123Z"
    }
   },
   "outputs": [],
   "source": [
    "mainFolder = \"/data/Sandra/2019/2019_07_01/\"\n",
    "# mainFolder = \"/data/Marjan/MB2020_lifs_2_2/Arginine-photon-counting/\"\n",
    "# mainFolder = \"/data/Sandra/2019/2019_09_03/\"\n",
    "\n",
    "\n",
    "recordings = []\n",
    "for cur,ds,fs in os.walk(mainFolder):\n",
    "    #### if you wish to restrict to only certain folders: ####\n",
    "#     if \"2020_11_05\" not in cur: continue\n",
    "    for f in fs:\n",
    "        if not (f.endswith(\".lif\")):# or f.endswith(\".nd2\")):\n",
    "            continue\n",
    "        path = os.path.join(cur,f)\n",
    "        recordings += [path]\n",
    "recordings = sorted(recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T09:33:31.227763Z",
     "start_time": "2020-11-19T09:33:31.068686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53703494a3a347909711f2f981bae8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### /data/Sandra/2019/2019_07_01/Experiment22.lif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status_orig = import_data(recordings, forceMetadataParse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T09:33:33.444651Z",
     "start_time": "2020-11-19T09:33:33.427537Z"
    }
   },
   "outputs": [],
   "source": [
    "# for _,row in status_orig.iterrows():\n",
    "#     print (f\"\"\"/data/useful_notebooks/process_single.py --rec='{row.path}' --ser='{row.series}' --verbose\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T09:33:33.655086Z",
     "start_time": "2020-11-19T09:33:33.617563Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# recast for presentation\n",
    "status = deepcopy(status_orig)\n",
    "status.pxSize = status.pxSize.apply(\"{:.3f}\".format).astype(\"str\")\n",
    "for c in status.columns:\n",
    "    if \"Size\" in c and \"px\" not in c:\n",
    "        status[c.replace(\"Size\",\"\")] = status[c]\n",
    "        del status[c]\n",
    "\n",
    "status[\"location\"] = status.path.apply(lambda xi: os.path.split(xi)[0])\n",
    "status[\"Freq\"] = status[\"Frequency\"].apply(\"{:.1f}\".format).astype(\"str\")\n",
    "del status[\"Frequency\"]\n",
    "status[\"Duration\"] = status[\"Duration\"].apply(str).apply(lambda xi: xi.split()[-1].split(\".\")[0] )\n",
    "\n",
    "firstCols = [\"exp\", \"series\",\"movie\",\"Freq\",\"Duration\", \"movie size [MB]\", ]#,\"images\",]\n",
    "status = status[[c for c in firstCols if c in status]+[c for c in status.columns if c not in firstCols]]\n",
    "lastCols = [\"path\"]\n",
    "status = status[[c for c in status.columns if c not in lastCols]+lastCols]\n",
    "\n",
    "if \"movie size [MB]\" in status:\n",
    "    status[\"movie size [MB]\"] = status[\"movie size [MB]\"].round(1)\n",
    "for col in [\n",
    "    \"pxUnit\",\n",
    "    \"frame_range\",\n",
    "    \"gap\",\n",
    "    \"pickles\"\n",
    "           ]:\n",
    "    if col in status:\n",
    "        del status[col]\n",
    "# if \"pickles\" in status:\n",
    "#     status.pickles = status_orig.pickles.apply(lambda xi: str(xi)[1:-1].replace(\" \",\"\") if \"[\" in str(xi) else \"\")\n",
    "\n",
    "# status = status[~status[list(\"XYZT\")].isna().all(1)]\n",
    "# status = status[status.Z==1]\n",
    "# status = status[~status[[\"movie\",\"(re)do pickles\"]].all(1)]\n",
    "# status = status[~status.exp.apply(lambda xi: xi.endswith(\"nd2\"))]\n",
    "# status = status[status_orig.Duration>pd.Timedelta(\"30s\")]\n",
    "# status[\"line_scan\"] = status[\"line scan\"].astype(int)\n",
    "\n",
    "status = status.sort_values([\"exp\",\"Y\"])\n",
    "status.index = range(len(status))\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "ix = status[status[\"line scan\"]==\"none\"].query(\"T<10\").index\n",
    "\n",
    "status = status.drop(index=ix)\n",
    "\n",
    "status.index = range(len(status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T09:33:33.990060Z",
     "start_time": "2020-11-19T09:33:33.777690Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "open the following link in a different tab (do not close this tab!): <a href=\"https://ctn.physiologie.meduniwien.ac.at/user/srdjan/app/endpoints/1c13012a74e34bbcb20270c354397983/\">https://ctn.physiologie.meduniwien.ac.at/user/srdjan/app/endpoints/1c13012a74e34bbcb20270c354397983/</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to hide\n",
    "nshow = len(status)\n",
    "htmltable = generate_table(status.iloc[:nshow,:-2], max_rows=nshow)\n",
    "ixOrder = OrderedDict([(f\"table-{col}-{i}\",{\"col\":col,\"index\":i}) \\\n",
    "                       for i in range(nshow) for col in [\"movie\",\"(re)do pickles\",\"images done\"] \\\n",
    "                           if (col in status.columns) and (isinstance(status.loc[i,col],(bool,np.bool_)))\n",
    "                      ])\n",
    "\n",
    "app = JupyterDash(__name__, width=1000)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div(\"Please check which of the following series you wish processed into movies/pickles. When done, please click on the button and follow instructions.\"),\n",
    "    html.Br(),\n",
    "    html.Button(id=\"save\",children=[\"Prepare script\"],n_clicks=0),\n",
    "    html.Div(id=\"output\"),\n",
    "#     html.Button(id=\"check-all\",children=[\"Check all\"],n_clicks=0),\n",
    "    html.Div(htmltable,style={\"width\":\"1000px\"}),\n",
    "    html.Pre(id=\"marked\",children=\"------------\",\n",
    "             style={\n",
    "                \"width\": \"700px\",\n",
    "                \"height\": \"300px\",\n",
    "                'overflowX': 'scroll',\n",
    "                'overflowY': 'scroll',\n",
    "                \"display\": \"block\" if \"srdjan\" in os.getcwd() else \"none\",\n",
    "            }),\n",
    "],style={\"font-family\":\"Arial\"})\n",
    "\n",
    "inputs = [Input(k,\"value\") for k in ixOrder]\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"marked\",\"children\"),\n",
    "    inputs\n",
    ")\n",
    "def see(*manyinputs):\n",
    "    output = \"\"\n",
    "    try:\n",
    "        out = deepcopy(ixOrder)\n",
    "        for k,v in zip(out, manyinputs):\n",
    "            out[k][\"value\"] = v\n",
    "        out = list(out.values())\n",
    "        for el in out:\n",
    "            el[\"value\"] = bool(len(el[\"value\"]))\n",
    "            i = status.index[el[\"index\"]]\n",
    "            el[\"rec\"] = status.loc[i,\"path\"]\n",
    "            el[\"ser\"] = status.loc[i,\"series\"]\n",
    "            el[\"line scan\"] = status.loc[i,\"line scan\"]\n",
    "        out = pd.DataFrame(out)\n",
    "        checklist_parse = out.query(\"col=='images done'\").copy()\n",
    "        if len(checklist_parse):\n",
    "            del checklist_parse[\"col\"], checklist_parse[\"index\"], checklist_parse[\"value\"]\n",
    "        else: \n",
    "            checklist_parse = pd.DataFrame()\n",
    "        out = out.query(\"col!='images done'\")\n",
    "\n",
    "        for (rec,ser),ddf in out.groupby([\"rec\",\"ser\"]):\n",
    "            el = {\"rec\":rec,\"ser\":ser}\n",
    "            el[\"movie\"] = ddf.query(\"col=='movie'\")[\"value\"].iloc[0]\n",
    "            el[\"pickles\"] = ddf.query(\"col=='(re)do pickles'\")[\"value\"].iloc[0]\n",
    "            el[\"line scan\"] = \"none\"\n",
    "            checklist_parse = checklist_parse.append(el,ignore_index=True)\n",
    "        ################################### good begin\n",
    "        allrecs = checklist_parse.rec.unique()\n",
    "#         output += \"\\n\"+checklist_parse.__repr__()\n",
    "\n",
    "        for rec in np.unique(allrecs):\n",
    "            outFile = \"/.\".join(os.path.split(rec))+\".out\"\n",
    "            output += f\"rm {outFile}\\n\"\n",
    "        for _,row in checklist_parse.iterrows():\n",
    "            if row[\"line scan\"]==\"none\":\n",
    "                if not row[[\"movie\",\"pickles\"]].any():\n",
    "                    continue\n",
    "            outFile = \"/.\".join(os.path.split(row.rec))+\".out\"\n",
    "            line = f'echo \"\" >> {outFile}\\n'\n",
    "            line += f'echo \"\" >> {outFile}\\n'\n",
    "            line += f'''echo \"{'#'*50}\" >> {outFile}\\n'''\n",
    "            line += f'''echo \"###### processing of {row.ser} started at: $(date)\" >> {outFile}\\n'''\n",
    "            line += f'''{{ time /data/useful_notebooks/process_single.py --recording=\"{row.rec}\" --series=\"{row.ser}\" --verbose'''\n",
    "\n",
    "            if row[\"line scan\"]!=\"none\":\n",
    "                line += \" --line-scan=\"+row[\"line scan\"]\n",
    "            else:\n",
    "                if not row.movie:\n",
    "                    line += \" --leave-movie\"\n",
    "                if not row.pickles:\n",
    "                    line += \" --leave-pickles\"\n",
    "            line += f\" >> {outFile} ; }} 2>> {outFile}\"\n",
    "            output += line+\"\\n\"\n",
    "        ################################### good end\n",
    "    except:\n",
    "        output += str(exc_info())\n",
    "    return output\n",
    "\n",
    "# @app.callback(\n",
    "#     [Output(k,\"value\") for k in ixOrder],\n",
    "#     [Input(\"check-all\",\"n_clicks\")]\n",
    "# )\n",
    "# def checkall(nc):\n",
    "#     if nc>0:\n",
    "#         if nc%2:\n",
    "#             return tuple([[None] for k in  ixOrder])\n",
    "#         else:\n",
    "#             return tuple([[] for k in  ixOrder])\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"output\",\"children\"),\n",
    "    [Input(\"save\",\"n_clicks\")],\n",
    "    [State(\"marked\",\"children\")]\n",
    ")\n",
    "def prepare_script(n_clicks, text):\n",
    "    if n_clicks>0:\n",
    "        with open(os.path.expanduser(\"~/processing_script.sh\"),\"w\") as f:\n",
    "            f.write(text)\n",
    "        return dcc.Markdown(\"\"\"`processing_script.sh` prepared in your home folder.\n",
    "\n",
    "Just open new terminal and run: `bash processing_script.sh` \n",
    "\n",
    "You can then close the window and wait until the processing is finished. \n",
    "\n",
    "_(For now, there is no reallyt good way how to follow progress, sorry. You can try the cell below...)_\n",
    "\"\"\")\n",
    "\n",
    "app._repr_html_() \n",
    "link2app = \"https://ctn.physiologie.meduniwien.ac.at\"+app.get_app_root_url()\n",
    "HTML(f'open the following link in a different tab (do not close this tab!): <a href=\"{link2app}\">{link2app}</a>')\n",
    "# app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:13:16.197493Z",
     "start_time": "2020-10-04T02:13:16.174195Z"
    }
   },
   "source": [
    "#### Hacky way to check progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:13:16.197493Z",
     "start_time": "2020-10-04T02:13:16.174195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for exp,df in status.groupby(\"exp\"):\n",
    "    printExp = True\n",
    "    for i,row in df.iterrows():\n",
    "#         assert (status.loc[i].iloc[:2] == status_orig.loc[i,[\"exp\",\"series\"]]).all()\n",
    "        try:\n",
    "            images = [f\".image_{'%i.%i'%fs if isinstance(fs,tuple) else fs}.png\" for fs in status_orig.loc[i,\"pickles\"] ]\n",
    "        except:\n",
    "            continue\n",
    "        serDir = f\"{row.path}_analysis/{row.series}\"\n",
    "        if os.path.isdir(serDir):\n",
    "            imDone = sum([el in images for el in os.listdir(serDir)])\n",
    "        else:\n",
    "            imDone = 0\n",
    "        outPutFile = row.path.replace(row.exp, \".\"+row.exp+\".out\")\n",
    "        percDone = 100/len(images)*imDone\n",
    "    #     if percDone>=100: continue\n",
    "        print (\"%20s %13s  %3i%%\"%(row.exp if printExp else \"\", row.series, percDone))#, outPutFile, os.path.isfile(outPutFile))\n",
    "    #     if os.path.isfile(outPutFile):\n",
    "    #         output = open(outPutFile).read()\n",
    "    #         last = output#-1]\n",
    "    #         last = \"\\n\".join([\"\\t\"+l for l in last.splitlines()])\n",
    "    #         last += \"\\n\"\n",
    "    #         print(last)\n",
    "\n",
    "    #     break\n",
    "        printExp = False\n",
    "    print (\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Physio",
   "language": "python",
   "name": "physio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
